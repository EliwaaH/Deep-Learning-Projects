{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgT6BGDJ4oxCU4BQlW63ya",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EliwaaH/Deep-Learning-Projects/blob/main/Cats%26Dogs%20Using%20Transfer%20Learning(Features%20Extraction).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we will use Kaggel cats and dogs dataset and we will build a classifier using Tensorflow and Keras from scratch.\n",
        "\n",
        "This is the first part of three parts project which contains\n",
        "\n",
        "\n",
        "*   Cats & Dogs classifier from scratch\n",
        "*   **Cats & Dogs classifier using Feature Extraction method (This notebook)**\n",
        "\n",
        "*   Cats & Dogs classifier using Fine Tuning method\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tt9WUGCkuRhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import zipfile \n",
        "import shutil\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.image as mpimg\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Hm53udBKvJad"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\" \\\n",
        "    -O \"/content/catsVdogs.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iOfquoF2U52",
        "outputId": "71ac625c-1da6-493a-d963-d5ce8a7175f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-23 18:02:16--  https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.72.44.156, 2600:1413:a000:6bb::317f, 2600:1413:a000:682::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.72.44.156|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 824887076 (787M) [application/octet-stream]\n",
            "Saving to: ‘/content/catsVdogs.zip’\n",
            "\n",
            "/content/catsVdogs. 100%[===================>] 786.67M   261MB/s    in 3.0s    \n",
            "\n",
            "2022-09-23 18:02:20 (261 MB/s) - ‘/content/catsVdogs.zip’ saved [824887076/824887076]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, we are zipping our downloaded dataset and extract it in our working directory \n",
        "\n",
        "local_zip = \"/content/catsVdogs.zip\"\n",
        "zip_file = zipfile.ZipFile(local_zip, 'r')\n",
        "current_dir = os.getcwd()\n",
        "zip_file.extractall(current_dir)\n",
        "zip_file.close()"
      ],
      "metadata": {
        "id": "hbFt7Lqz4SUt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_path = '/content/PetImages'\n",
        "\n",
        "source_path_cats = os.path.join(source_path, 'Cat')\n",
        "source_path_dogs = os.path.join(source_path, 'Dog')\n",
        "\n",
        "# Here, we are removing any file that doesn't has the file format jpg in our working files\n",
        "!find /content/PetImages/ -type f ! -name \"*.jpg\" -exec rm {} +\n",
        "\n",
        "print(f'Found {len(os.listdir(source_path_cats))} images of cats')\n",
        "print(f'Found {len(os.listdir(source_path_dogs))} images of dogs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssPSurS85JCf",
        "outputId": "ae856d1c-6b89-4320-874b-c88deb60cd7c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12500 images of cats\n",
            "Found 12500 images of dogs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, After downloading our data and clean it we have to prepare our training and validation directories to copy cats and dogs images in it"
      ],
      "metadata": {
        "id": "kwfxB0MR_5id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and Validation Directories Preparation\n",
        "\n",
        "def create_train_valid_dirs():\n",
        "  \n",
        "  cur_dir = os.getcwd()\n",
        "\n",
        "  \n",
        "  #Checking if the main directory is already exists or not, if exist so delete the whole directroy\n",
        "  if os.path.exists(os.path.join(f'{cur_dir}/catsVdogs')):\n",
        "    shutil.rmtree(os.path.join(f'{cur_dir}/catsVdogs'))\n",
        "\n",
        "  #creating the main directory\n",
        "  os.mkdir(os.path.join(cur_dir, 'catsVdogs'))\n",
        "\n",
        "\n",
        "  #creatin the training directory\n",
        "  os.mkdir(os.path.join(f'{cur_dir}/catsVdogs', 'training'))\n",
        "  os.mkdir(os.path.join(f'{cur_dir}/catsVdogs/training', 'cats'))\n",
        "  os.mkdir(os.path.join(f'{cur_dir}/catsVdogs/training', 'dogs'))\n",
        "  \n",
        "  #creating the validation directory\n",
        "  os.mkdir(os.path.join(f'{cur_dir}/catsVdogs', 'validation'))\n",
        "  os.mkdir(os.path.join(f'{cur_dir}/catsVdogs/validation', 'cats'))\n",
        "  os.mkdir(os.path.join(f'{cur_dir}/catsVdogs/validation', 'dogs'))\n",
        "\n",
        "  pass\n",
        "\n",
        "create_train_valid_dirs()"
      ],
      "metadata": {
        "id": "788PouIv-bLu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is splitting our data into validation and training samples, so we will create a function that will do some steps on data before splitting\n",
        "\n",
        "1.   Randomize our data by shuffling it by using (random.sample(list, len(list))\n",
        "2.   Check if there's any image that doesn't have a size(undefined image)\n",
        "\n",
        "1.   Splitting our data by a ratio that we will define\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wZce52mwVy4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(source_dir, training_dir, validation_dir, split_size):\n",
        "  \n",
        "  shuffled_data = random.sample(list(os.listdir(source_dir)), len(os.listdir(source_dir)))\n",
        "  training_number = int(len(shuffled_data) * split_size)\n",
        "\n",
        "  i = 0\n",
        "  dir = training_dir\n",
        "\n",
        "  for im in shuffled_data:\n",
        "    image_source = os.path.join(source_dir, im)\n",
        "\n",
        "    if i == training_number:\n",
        "      dir = validation_dir\n",
        "    \n",
        "    i += 1\n",
        "\n",
        "    if os.path.getsize(image_source) == 0:\n",
        "      print(f'{im} is zero lentgh, so ignoring')\n",
        "\n",
        "    else:\n",
        "      copyfile(image_source, os.path.join(dir, im))\n",
        "\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "rNJHhwQ7HY0b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After creating our function we have to define our paths and check the number of images that will fly to our image generators which will be the input for our classifier."
      ],
      "metadata": {
        "id": "OxKC4mxNfRSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CAT_DIRECTORY = '/content/PetImages/Cat/'\n",
        "DOG_DIRECTORY = '/content/PetImages/Dog/'\n",
        "\n",
        "TRAINING_CAT_DIR = '/content/catsVdogs/training/cats/'\n",
        "TRAINING_DOG_DIR = '/content/catsVdogs/training/dogs/'\n",
        "VALIDATION_CAT_DIR = '/content/catsVdogs/validation/cats/'\n",
        "VALIDATION_DOG_DIR = '/content/catsVdogs/validation/dogs/'\n",
        "\n",
        "\n",
        "if len(os.listdir(TRAINING_CAT_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_CAT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(TRAINING_DOG_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_DOG_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_CAT_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_CAT_DIR):\n",
        "    os.remove(file.path)\n",
        "if len(os.listdir(VALIDATION_DOG_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_DOG_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "split_data(CAT_DIRECTORY, TRAINING_CAT_DIR, VALIDATION_CAT_DIR, 0.9)\n",
        "split_data(DOG_DIRECTORY, TRAINING_DOG_DIR, VALIDATION_DOG_DIR, 0.9)\n",
        "\n",
        "print(f\"\\n\\nThere are {len(os.listdir(TRAINING_CAT_DIR))} images of cats for training\")\n",
        "print(f\"There are {len(os.listdir(TRAINING_DOG_DIR))} images of dogs for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_CAT_DIR))} images of cats for testing\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_DOG_DIR))} images of dogs for testing\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ4yX5JDZhKc",
        "outputId": "f66bc145-7493-46e7-854a-baa0d5e9e859"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666.jpg is zero lentgh, so ignoring\n",
            "11702.jpg is zero lentgh, so ignoring\n",
            "\n",
            "\n",
            "There are 11249 images of cats for training\n",
            "There are 11249 images of dogs for training\n",
            "There are 1250 images of cats for testing\n",
            "There are 1250 images of dogs for testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are in the last part of preparing our data which is making the genrators that will be the classifier input.\n",
        "\n",
        "Generators are very useful keras image API that can do a lot of operations to our data before going to the classifier like AUGMENTAION."
      ],
      "metadata": {
        "id": "1mUoLFo-kitb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "\n",
        "  train_data = ImageDataGenerator(\n",
        "      rescale=1./255.,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest'\n",
        "  )\n",
        "\n",
        "  train_generator=train_data.flow_from_directory(\n",
        "      directory = TRAINING_DIR,\n",
        "      batch_size = 128, \n",
        "      class_mode='binary',\n",
        "      target_size = (150, 150)\n",
        "  )\n",
        "\n",
        "  valid_data = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "  validation_generator = valid_data.flow_from_directory(\n",
        "      directory = VALIDATION_DIR, \n",
        "      batch_size = 32, \n",
        "      class_mode='binary',\n",
        "      target_size = (150, 150)\n",
        "  )\n",
        "\n",
        "  return train_generator, validation_generator\n",
        "\n"
      ],
      "metadata": {
        "id": "Wi8MvYk2esNM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = '/content/catsVdogs/training/'\n",
        "VALIDATION_DIR = '/content/catsVdogs/validation/'\n",
        "\n",
        "train_generator, validation_generator= create_image_generators(TRAINING_DIR, VALIDATION_DIR)\n"
      ],
      "metadata": {
        "id": "oHYm-bsznBBn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43afb7a1-0f58-49a5-966a-1b4ea2818518"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22498 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see our Image generators successfuly defined two classes for every directory"
      ],
      "metadata": {
        "id": "8sb1tG1Ps9YT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here is the different part of the previous notebook becuase here we will use Transfer Learning (Feature Extraction), so we will download a model which will be the Inception_V3 model and we will use it's pretrained weights to extract our features from our teaining dataset.**"
      ],
      "metadata": {
        "id": "Zlljh4pyMYxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First thing to do is to download the models' weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL7l2C9xKO0e",
        "outputId": "a322d928-9ecc-4537-c1cd-bf1de27824ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-23 18:02:33--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.128, 74.125.68.128, 142.250.4.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/content/inception_ 100%[===================>]  83.84M   119MB/s    in 0.7s    \n",
            "\n",
            "2022-09-23 18:02:34 (119 MB/s) - ‘/content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second, We will load the model from keras library and save the path to it's weights\n",
        "\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "downloaded_weights = '/content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'"
      ],
      "metadata": {
        "id": "_nR8NE2fOUHt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_base_model(downloaded_weights):\n",
        "  \n",
        "  ## now we create a function that will preapre our base model\n",
        "\n",
        "  base_model = InceptionV3(\n",
        "      input_shape=(150, 150, 3),\n",
        "      include_top=False,\n",
        "      weights = None\n",
        "  )\n",
        "\n",
        "  # We pass our dowloaded weights to our base model\n",
        "  base_model.load_weights(downloaded_weights)\n",
        "\n",
        "  # This step is so important because here we are make all our base model layers untrainable and this what we are need\n",
        "  # our model to change any of it's weights we just excluded it's top layer which will be replaced by our calssification layers\n",
        "  base_model.trainable = False\n",
        "\n",
        "  return base_model"
      ],
      "metadata": {
        "id": "qoR4hek5POmS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Here we will see the model layers and see what is the layer that we will take it as an input to our calssifier.\n",
        "\n",
        "base_model = create_base_model(downloaded_weights)\n",
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he0QMDWYRkhw",
        "outputId": "4d60fe37-2080-4a76-a547-ebd458d7296f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Here we are making sure that all the parameters of our base model are untrainable to avoid any overwrtiting or changing in our base model.\n",
        "\n",
        "total_params = base_model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in base_model.trainable_weights])\n",
        "\n",
        "print(f'There are {total_params:,} total parameters in this model ')\n",
        "print(f'There are {num_trainable_params} trainable parameters in this model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df4pYpspR9Z7",
        "outputId": "5e7dda56-c2e7-41f1-8de1-724ee36e890b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 21,802,784 total parameters in this model \n",
            "There are 0 trainable parameters in this model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Here we are making a CallBack to stop the training process when reached to a specific accuracy to avoid any wasting of time\n",
        "\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') > 0.999):\n",
        "      print(\"\\nReached 99.9 accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "ZAT9RxF6XBzb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to create our model and build our DNN from scratch using tensorflow and keras"
      ],
      "metadata": {
        "id": "dvUilXXotQLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Here we are building our model which based on Base model and a classifications layers that will be our model output for our problem\n",
        "\n",
        "def create_model(base_model):\n",
        "\n",
        "  inputs = Input(shape=(150, 150, 3))\n",
        "  x = base_model(inputs, training=False)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs = inputs, outputs =  x)\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "vLtnbGv1tNNd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## As we can see here after adding our classifications layers for our base model, Now we have a trainable parameters that we can train them\n",
        "\n",
        "model = create_model(base_model)\n",
        "total_params = model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])\n",
        "\n",
        "print(f'There are {total_params:,} total parameters in this model ')\n",
        "print(f'There are {num_trainable_params:,} trainable parameters in this model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSRwy0x0e50D",
        "outputId": "a2c01097-aac3-4569-f63f-61aa0d56c66a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 40,679,201 total parameters in this model \n",
            "There are 18,876,417 trainable parameters in this model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## In this cell we are complining our model with a very low learning rate to try to get the best accuracy for training\n",
        "## We use ADAM optimizer also we can use for this problem The RMSprop optimizer which will be good here too\n",
        "## we have to use a proper loss function, This depending on our problem which here is a 0 or 1 classification\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=0.00001), \n",
        "             loss = 'binary_crossentropy', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "C2_qfTBX0B1n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = MyCallback()\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs = 100, \n",
        "    verbose = 1,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFUISjIV17ua",
        "outputId": "4095248e-db5b-41bb-b4eb-40766d03a523"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 167s 947ms/step - loss: 0.2009 - accuracy: 0.9209 - val_loss: 0.0843 - val_accuracy: 0.9712\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 161s 917ms/step - loss: 0.1706 - accuracy: 0.9302 - val_loss: 0.0764 - val_accuracy: 0.9712\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 161s 914ms/step - loss: 0.1592 - accuracy: 0.9352 - val_loss: 0.0767 - val_accuracy: 0.9736\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 161s 913ms/step - loss: 0.1521 - accuracy: 0.9376 - val_loss: 0.0778 - val_accuracy: 0.9732\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 161s 917ms/step - loss: 0.1499 - accuracy: 0.9387 - val_loss: 0.0777 - val_accuracy: 0.9732\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 162s 919ms/step - loss: 0.1422 - accuracy: 0.9408 - val_loss: 0.0784 - val_accuracy: 0.9724\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 161s 915ms/step - loss: 0.1418 - accuracy: 0.9404 - val_loss: 0.0683 - val_accuracy: 0.9752\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 163s 924ms/step - loss: 0.1335 - accuracy: 0.9448 - val_loss: 0.0742 - val_accuracy: 0.9744\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 162s 922ms/step - loss: 0.1351 - accuracy: 0.9431 - val_loss: 0.0732 - val_accuracy: 0.9748\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 161s 914ms/step - loss: 0.1289 - accuracy: 0.9479 - val_loss: 0.0667 - val_accuracy: 0.9752\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 161s 916ms/step - loss: 0.1321 - accuracy: 0.9456 - val_loss: 0.0694 - val_accuracy: 0.9732\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 160s 906ms/step - loss: 0.1269 - accuracy: 0.9477 - val_loss: 0.0664 - val_accuracy: 0.9748\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 160s 907ms/step - loss: 0.1266 - accuracy: 0.9491 - val_loss: 0.0693 - val_accuracy: 0.9736\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 160s 910ms/step - loss: 0.1206 - accuracy: 0.9507 - val_loss: 0.0714 - val_accuracy: 0.9748\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 160s 910ms/step - loss: 0.1276 - accuracy: 0.9454 - val_loss: 0.0670 - val_accuracy: 0.9756\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 162s 918ms/step - loss: 0.1204 - accuracy: 0.9500 - val_loss: 0.0664 - val_accuracy: 0.9760\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 161s 914ms/step - loss: 0.1223 - accuracy: 0.9509 - val_loss: 0.0654 - val_accuracy: 0.9756\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 161s 913ms/step - loss: 0.1222 - accuracy: 0.9503 - val_loss: 0.0659 - val_accuracy: 0.9752\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 161s 915ms/step - loss: 0.1210 - accuracy: 0.9509 - val_loss: 0.0744 - val_accuracy: 0.9732\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 160s 911ms/step - loss: 0.1161 - accuracy: 0.9508 - val_loss: 0.0648 - val_accuracy: 0.9740\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 161s 914ms/step - loss: 0.1187 - accuracy: 0.9506 - val_loss: 0.0711 - val_accuracy: 0.9724\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 160s 911ms/step - loss: 0.1134 - accuracy: 0.9525 - val_loss: 0.0640 - val_accuracy: 0.9752\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 160s 909ms/step - loss: 0.1166 - accuracy: 0.9517 - val_loss: 0.0746 - val_accuracy: 0.9704\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 161s 916ms/step - loss: 0.1105 - accuracy: 0.9561 - val_loss: 0.0619 - val_accuracy: 0.9776\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 160s 909ms/step - loss: 0.1123 - accuracy: 0.9539 - val_loss: 0.0654 - val_accuracy: 0.9748\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 159s 906ms/step - loss: 0.1121 - accuracy: 0.9536 - val_loss: 0.0626 - val_accuracy: 0.9760\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 160s 909ms/step - loss: 0.1130 - accuracy: 0.9537 - val_loss: 0.0645 - val_accuracy: 0.9760\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 159s 906ms/step - loss: 0.1056 - accuracy: 0.9568 - val_loss: 0.0649 - val_accuracy: 0.9780\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.1071 - accuracy: 0.9572 - val_loss: 0.0680 - val_accuracy: 0.9756\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.1110 - accuracy: 0.9551 - val_loss: 0.0682 - val_accuracy: 0.9768\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 162s 920ms/step - loss: 0.1064 - accuracy: 0.9558 - val_loss: 0.0618 - val_accuracy: 0.9780\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.1070 - accuracy: 0.9571 - val_loss: 0.0606 - val_accuracy: 0.9764\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 159s 903ms/step - loss: 0.1061 - accuracy: 0.9567 - val_loss: 0.0695 - val_accuracy: 0.9752\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.1024 - accuracy: 0.9588 - val_loss: 0.0643 - val_accuracy: 0.9764\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.1052 - accuracy: 0.9588 - val_loss: 0.0578 - val_accuracy: 0.9792\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 160s 910ms/step - loss: 0.1050 - accuracy: 0.9579 - val_loss: 0.0630 - val_accuracy: 0.9784\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.1026 - accuracy: 0.9592 - val_loss: 0.0619 - val_accuracy: 0.9764\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 161s 913ms/step - loss: 0.1015 - accuracy: 0.9599 - val_loss: 0.0597 - val_accuracy: 0.9792\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 161s 913ms/step - loss: 0.0998 - accuracy: 0.9591 - val_loss: 0.0641 - val_accuracy: 0.9768\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 161s 913ms/step - loss: 0.1006 - accuracy: 0.9594 - val_loss: 0.0623 - val_accuracy: 0.9772\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 160s 911ms/step - loss: 0.0968 - accuracy: 0.9602 - val_loss: 0.0756 - val_accuracy: 0.9740\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 162s 918ms/step - loss: 0.1000 - accuracy: 0.9590 - val_loss: 0.0632 - val_accuracy: 0.9780\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 160s 909ms/step - loss: 0.0997 - accuracy: 0.9578 - val_loss: 0.0662 - val_accuracy: 0.9752\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 160s 911ms/step - loss: 0.0980 - accuracy: 0.9612 - val_loss: 0.0677 - val_accuracy: 0.9748\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 159s 906ms/step - loss: 0.0964 - accuracy: 0.9620 - val_loss: 0.0589 - val_accuracy: 0.9784\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 162s 919ms/step - loss: 0.0987 - accuracy: 0.9600 - val_loss: 0.0610 - val_accuracy: 0.9788\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 160s 910ms/step - loss: 0.0981 - accuracy: 0.9607 - val_loss: 0.0621 - val_accuracy: 0.9764\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 162s 919ms/step - loss: 0.0970 - accuracy: 0.9616 - val_loss: 0.0648 - val_accuracy: 0.9760\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 165s 938ms/step - loss: 0.0969 - accuracy: 0.9606 - val_loss: 0.0624 - val_accuracy: 0.9756\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 163s 928ms/step - loss: 0.0933 - accuracy: 0.9626 - val_loss: 0.0675 - val_accuracy: 0.9752\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 162s 921ms/step - loss: 0.0945 - accuracy: 0.9616 - val_loss: 0.0635 - val_accuracy: 0.9744\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 162s 920ms/step - loss: 0.0896 - accuracy: 0.9632 - val_loss: 0.0652 - val_accuracy: 0.9748\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 160s 909ms/step - loss: 0.0922 - accuracy: 0.9638 - val_loss: 0.0631 - val_accuracy: 0.9776\n",
            "Epoch 54/100\n",
            "176/176 [==============================] - 160s 910ms/step - loss: 0.0940 - accuracy: 0.9620 - val_loss: 0.0586 - val_accuracy: 0.9796\n",
            "Epoch 55/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.0931 - accuracy: 0.9611 - val_loss: 0.0637 - val_accuracy: 0.9776\n",
            "Epoch 56/100\n",
            "176/176 [==============================] - 160s 908ms/step - loss: 0.0914 - accuracy: 0.9636 - val_loss: 0.0659 - val_accuracy: 0.9760\n",
            "Epoch 57/100\n",
            "176/176 [==============================] - 160s 908ms/step - loss: 0.0887 - accuracy: 0.9657 - val_loss: 0.0666 - val_accuracy: 0.9764\n",
            "Epoch 58/100\n",
            "176/176 [==============================] - 185s 1s/step - loss: 0.0924 - accuracy: 0.9635 - val_loss: 0.0645 - val_accuracy: 0.9796\n",
            "Epoch 59/100\n",
            "176/176 [==============================] - 189s 1s/step - loss: 0.0892 - accuracy: 0.9648 - val_loss: 0.0606 - val_accuracy: 0.9776\n",
            "Epoch 60/100\n",
            "176/176 [==============================] - 160s 910ms/step - loss: 0.0883 - accuracy: 0.9647 - val_loss: 0.0636 - val_accuracy: 0.9776\n",
            "Epoch 61/100\n",
            "176/176 [==============================] - 160s 909ms/step - loss: 0.0928 - accuracy: 0.9636 - val_loss: 0.0704 - val_accuracy: 0.9764\n",
            "Epoch 62/100\n",
            "176/176 [==============================] - 161s 912ms/step - loss: 0.0903 - accuracy: 0.9648 - val_loss: 0.0674 - val_accuracy: 0.9740\n",
            "Epoch 63/100\n",
            "176/176 [==============================] - 160s 907ms/step - loss: 0.0908 - accuracy: 0.9630 - val_loss: 0.0650 - val_accuracy: 0.9752\n",
            "Epoch 64/100\n",
            "176/176 [==============================] - 159s 905ms/step - loss: 0.0866 - accuracy: 0.9657 - val_loss: 0.0621 - val_accuracy: 0.9772\n",
            "Epoch 65/100\n",
            "176/176 [==============================] - 159s 900ms/step - loss: 0.0858 - accuracy: 0.9651 - val_loss: 0.0655 - val_accuracy: 0.9768\n",
            "Epoch 66/100\n",
            "176/176 [==============================] - 158s 899ms/step - loss: 0.0890 - accuracy: 0.9645 - val_loss: 0.0679 - val_accuracy: 0.9732\n",
            "Epoch 67/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.0844 - accuracy: 0.9676 - val_loss: 0.0665 - val_accuracy: 0.9768\n",
            "Epoch 68/100\n",
            "176/176 [==============================] - 158s 899ms/step - loss: 0.0845 - accuracy: 0.9679 - val_loss: 0.0665 - val_accuracy: 0.9748\n",
            "Epoch 69/100\n",
            "176/176 [==============================] - 160s 910ms/step - loss: 0.0828 - accuracy: 0.9669 - val_loss: 0.0665 - val_accuracy: 0.9760\n",
            "Epoch 70/100\n",
            "176/176 [==============================] - 160s 908ms/step - loss: 0.0831 - accuracy: 0.9676 - val_loss: 0.0652 - val_accuracy: 0.9792\n",
            "Epoch 71/100\n",
            "176/176 [==============================] - 159s 900ms/step - loss: 0.0853 - accuracy: 0.9655 - val_loss: 0.0615 - val_accuracy: 0.9792\n",
            "Epoch 72/100\n",
            "176/176 [==============================] - 159s 905ms/step - loss: 0.0811 - accuracy: 0.9675 - val_loss: 0.0636 - val_accuracy: 0.9776\n",
            "Epoch 73/100\n",
            "176/176 [==============================] - 159s 901ms/step - loss: 0.0819 - accuracy: 0.9678 - val_loss: 0.0611 - val_accuracy: 0.9784\n",
            "Epoch 74/100\n",
            "176/176 [==============================] - 158s 899ms/step - loss: 0.0826 - accuracy: 0.9681 - val_loss: 0.0644 - val_accuracy: 0.9768\n",
            "Epoch 75/100\n",
            "176/176 [==============================] - 160s 907ms/step - loss: 0.0810 - accuracy: 0.9684 - val_loss: 0.0619 - val_accuracy: 0.9792\n",
            "Epoch 76/100\n",
            "176/176 [==============================] - 159s 903ms/step - loss: 0.0821 - accuracy: 0.9680 - val_loss: 0.0600 - val_accuracy: 0.9788\n",
            "Epoch 77/100\n",
            "176/176 [==============================] - 160s 907ms/step - loss: 0.0806 - accuracy: 0.9667 - val_loss: 0.0627 - val_accuracy: 0.9772\n",
            "Epoch 78/100\n",
            "176/176 [==============================] - 159s 902ms/step - loss: 0.0804 - accuracy: 0.9674 - val_loss: 0.0641 - val_accuracy: 0.9792\n",
            "Epoch 79/100\n",
            "176/176 [==============================] - 160s 907ms/step - loss: 0.0767 - accuracy: 0.9702 - val_loss: 0.0642 - val_accuracy: 0.9772\n",
            "Epoch 80/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.0795 - accuracy: 0.9685 - val_loss: 0.0694 - val_accuracy: 0.9792\n",
            "Epoch 81/100\n",
            "176/176 [==============================] - 159s 901ms/step - loss: 0.0784 - accuracy: 0.9692 - val_loss: 0.0644 - val_accuracy: 0.9796\n",
            "Epoch 82/100\n",
            "176/176 [==============================] - 159s 905ms/step - loss: 0.0811 - accuracy: 0.9662 - val_loss: 0.0675 - val_accuracy: 0.9768\n",
            "Epoch 83/100\n",
            "176/176 [==============================] - 158s 898ms/step - loss: 0.0779 - accuracy: 0.9695 - val_loss: 0.0801 - val_accuracy: 0.9744\n",
            "Epoch 84/100\n",
            "176/176 [==============================] - 159s 905ms/step - loss: 0.0778 - accuracy: 0.9685 - val_loss: 0.0641 - val_accuracy: 0.9764\n",
            "Epoch 85/100\n",
            "176/176 [==============================] - 159s 901ms/step - loss: 0.0767 - accuracy: 0.9688 - val_loss: 0.0704 - val_accuracy: 0.9752\n",
            "Epoch 86/100\n",
            "176/176 [==============================] - 160s 909ms/step - loss: 0.0756 - accuracy: 0.9687 - val_loss: 0.0734 - val_accuracy: 0.9748\n",
            "Epoch 87/100\n",
            "176/176 [==============================] - 159s 901ms/step - loss: 0.0778 - accuracy: 0.9696 - val_loss: 0.0632 - val_accuracy: 0.9768\n",
            "Epoch 88/100\n",
            "176/176 [==============================] - 158s 899ms/step - loss: 0.0753 - accuracy: 0.9712 - val_loss: 0.0668 - val_accuracy: 0.9756\n",
            "Epoch 89/100\n",
            "176/176 [==============================] - 159s 902ms/step - loss: 0.0763 - accuracy: 0.9688 - val_loss: 0.0651 - val_accuracy: 0.9780\n",
            "Epoch 90/100\n",
            "176/176 [==============================] - 159s 901ms/step - loss: 0.0764 - accuracy: 0.9691 - val_loss: 0.0659 - val_accuracy: 0.9780\n",
            "Epoch 91/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.0764 - accuracy: 0.9685 - val_loss: 0.0647 - val_accuracy: 0.9780\n",
            "Epoch 92/100\n",
            "176/176 [==============================] - 160s 906ms/step - loss: 0.0788 - accuracy: 0.9679 - val_loss: 0.0681 - val_accuracy: 0.9768\n",
            "Epoch 93/100\n",
            "176/176 [==============================] - 159s 904ms/step - loss: 0.0769 - accuracy: 0.9695 - val_loss: 0.0629 - val_accuracy: 0.9748\n",
            "Epoch 94/100\n",
            "176/176 [==============================] - 159s 902ms/step - loss: 0.0777 - accuracy: 0.9692 - val_loss: 0.0727 - val_accuracy: 0.9768\n",
            "Epoch 95/100\n",
            "176/176 [==============================] - 160s 907ms/step - loss: 0.0750 - accuracy: 0.9710 - val_loss: 0.0603 - val_accuracy: 0.9788\n",
            "Epoch 96/100\n",
            "176/176 [==============================] - 158s 900ms/step - loss: 0.0742 - accuracy: 0.9713 - val_loss: 0.0707 - val_accuracy: 0.9752\n",
            "Epoch 97/100\n",
            "176/176 [==============================] - 161s 912ms/step - loss: 0.0766 - accuracy: 0.9704 - val_loss: 0.0618 - val_accuracy: 0.9768\n",
            "Epoch 98/100\n",
            "176/176 [==============================] - 159s 902ms/step - loss: 0.0727 - accuracy: 0.9716 - val_loss: 0.0635 - val_accuracy: 0.9804\n",
            "Epoch 99/100\n",
            "176/176 [==============================] - 159s 905ms/step - loss: 0.0750 - accuracy: 0.9694 - val_loss: 0.0661 - val_accuracy: 0.9804\n",
            "Epoch 100/100\n",
            "176/176 [==============================] - 159s 903ms/step - loss: 0.0767 - accuracy: 0.9710 - val_loss: 0.0664 - val_accuracy: 0.9796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Last step in our notebook is to visualize the training results so we can see how our training and validation accuracies like, This help us to know at which point our model is getting to overfit and where is the best training point that the model reached to it during training."
      ],
      "metadata": {
        "id": "g9eXGFcXRfzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_accuracy = history.history['accuracy']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(training_accuracy))\n",
        "\n",
        "plt.plot(epochs, training_accuracy, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, validation_accuracy, 'b', \"Validation Accuracy\")\n",
        "plt.title(\"Training Validation Accuracy\")\n",
        "plt.show()\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "plt.plot(epochs, training_loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, validation_loss, 'b', \"Validation Loss\")\n",
        "plt.title(\" Training Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "p7C-o4vwPpp8",
        "outputId": "7cb4bdeb-8431-4efe-d8f7-ac83b4dd0bca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = os.listdir(os.path.join(\"/content/test_images/\"))\n",
        "\n",
        "for i in images:\n",
        "  path=\"/content/test_images/\" + i\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  x = image.img_to_array(img)\n",
        "  x /= 255.0\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images)\n",
        "\n",
        "\n",
        "  for n in classes:\n",
        "    if n[0] > 0.5:\n",
        "      print(f'the probability for image {i} is dog')\n",
        "    else:\n",
        "      print(f'the probability for image {i} is cat')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "pBRylAsMhAco",
        "outputId": "f11e0e4b-f5bf-4da9-e2ff-944f64b8517f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the probability for image cat1.jpg is dog\n",
            "the probability for image cat18.jpg is cat\n",
            "the probability for image dog1.jpg is dog\n",
            "the probability for image cat16.jpg is cat\n",
            "the probability for image cat19.jpg is cat\n",
            "the probability for image cat12.jpg is cat\n",
            "the probability for image cat7.jpg is cat\n",
            "the probability for image cat9.jpg is cat\n",
            "the probability for image cat15.jpg is dog\n",
            "the probability for image cat3.jpg is cat\n",
            "the probability for image cat20.jpg is dog\n",
            "the probability for image cat6.jpg is dog\n",
            "the probability for image cat2.jpg is cat\n",
            "the probability for image dog5.jpg is dog\n",
            "the probability for image dog3.jpg is dog\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-c4835b7fbbc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/test_images/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 314\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/test_images/.ipynb_checkpoints'"
          ]
        }
      ]
    }
  ]
}